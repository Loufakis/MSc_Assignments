{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "838574aa",
   "metadata": {},
   "source": [
    "# Violence Against Women"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c4d8aa2",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Set Up](#Set_Up)\n",
    "2. [Preprocessing](#Preprocessing)\n",
    "    1. [Split Datasetd](#Split_Datasetd)\n",
    "    2. [Remove Outliers](#Remove_Outliers)\n",
    "    3. [Impute](#Impute)\n",
    "    4. [Scale](#Scale)\n",
    "    5. [P.C.A.](#PCA)\n",
    "3. [Data Mining](#Data_Mining)\n",
    "    1. [Logistic Regression](#Logistic_Regression)\n",
    "    2. [k-Nearest Neighbors](#k_Nearest_Neighbors)\n",
    "    3. [Disicion Tree](#Disicion_Tree)\n",
    "    4. [Support Vector Machine](#Support_Vector_Machine)\n",
    "    5. [Random Forest](#Random_Forest)\n",
    "    6. [XGBoosting](#XGBoosting)\n",
    "4. [Evaluation-Interpretation](#Evaluation_Interpretation)\n",
    "5. [Prediction](#Prediction)\n",
    "    1. [Merge All Three SubDatasets Back to One](#Merge_All_Three_SubDatasets_Back_to_One)\n",
    "    2. [Save New Dataset as .csv](#Save_New_Dataset_as_.csv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b23e4e19",
   "metadata": {},
   "source": [
    "<a id=\"Set_Up\"></a>\n",
    "## Set_Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda679ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# Preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Evaluation\n",
    "from sklearn import metrics\n",
    "\n",
    "from utils import OUTCOME_ENCODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af3c263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Observation_Value</th>\n",
       "      <th>Age_15-49</th>\n",
       "      <th>Country_CK</th>\n",
       "      <th>Country_FJ</th>\n",
       "      <th>Country_FM</th>\n",
       "      <th>Country_KI</th>\n",
       "      <th>Country_MH</th>\n",
       "      <th>Country_NR</th>\n",
       "      <th>...</th>\n",
       "      <th>Prptr_FAMMAL</th>\n",
       "      <th>Prptr_NONPART</th>\n",
       "      <th>Prptr_OTHFEM</th>\n",
       "      <th>Prptr_OTHMAL</th>\n",
       "      <th>Prptr_PARTNER</th>\n",
       "      <th>Actual_ALO12M</th>\n",
       "      <th>Actual_ALOLIFE</th>\n",
       "      <th>L_Per_BEFORE15</th>\n",
       "      <th>L_Per_PREGNANCY</th>\n",
       "      <th>L_Per_SINCE15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>25</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>25</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>25</td>\n",
       "      <td>26.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>25</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>25</td>\n",
       "      <td>30.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time  Outcome  Observation_Value  Age_15-49  Country_CK  Country_FJ  \\\n",
       "0  2013       25                6.2          0           1           0   \n",
       "1  2013       25                9.6          0           1           0   \n",
       "2  2013       25               26.7          0           1           0   \n",
       "3  2013       25                6.7          0           1           0   \n",
       "4  2013       25               30.2          0           1           0   \n",
       "\n",
       "   Country_FM  Country_KI  Country_MH  Country_NR  ...  Prptr_FAMMAL  \\\n",
       "0           0           0           0           0  ...             0   \n",
       "1           0           0           0           0  ...             0   \n",
       "2           0           0           0           0  ...             0   \n",
       "3           0           0           0           0  ...             0   \n",
       "4           0           0           0           0  ...             0   \n",
       "\n",
       "   Prptr_NONPART  Prptr_OTHFEM  Prptr_OTHMAL  Prptr_PARTNER  Actual_ALO12M  \\\n",
       "0              0             0             0              1              0   \n",
       "1              0             0             0              1              1   \n",
       "2              0             0             0              1              0   \n",
       "3              0             0             0              1              1   \n",
       "4              0             0             0              1              0   \n",
       "\n",
       "   Actual_ALOLIFE  L_Per_BEFORE15  L_Per_PREGNANCY  L_Per_SINCE15  \n",
       "0               0               0                0              0  \n",
       "1               0               0                0              0  \n",
       "2               1               0                0              0  \n",
       "3               0               0                0              0  \n",
       "4               1               0                0              0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Preprocessed Data from WAV_Preprocessed.csv file\n",
    "data = pd.read_csv('datasets/WAV_Preprocessed.csv', \n",
    "                    # Specify the first row as the header\n",
    "                    header=0\n",
    "                    )\n",
    "\n",
    "# Take a look to make sure the data are correctly loaded\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7044542d",
   "metadata": {},
   "source": [
    "<a id=\"Preprocessing\"></a>\n",
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f6d3c8e",
   "metadata": {},
   "source": [
    "<a id=\"Split_Datasets\"></a>\n",
    "### Split Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e60aaa9a",
   "metadata": {},
   "source": [
    "Splitting the dataset into training and testing sets before performing preprocessing transformations is important to ensure that the preprocessing steps are performed consistently on both the training and testing sets. This helps to prevent information leakage, where information from the testing set is used to inform the preprocessing steps and artificially inflates the model's performance. By splitting the dataset first, we can ensure that the preprocessing steps are only informed by the training set, giving us a more accurate evaluation of the model's performance on the testing set. Additionally, this helps to ensure that the preprocessing steps are generalizable and can be applied to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "686a61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da6093d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (462, 68)\n",
      "y_train: (462,)\n",
      "X_test:  (82, 68)\n",
      "y_test:  (82,)\n",
      "X_pred: (1472, 68)\n",
      "y_pred: (1472,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and target sets\n",
    "# The target set will be used to predict missing values of the Outcome feature\n",
    "target_set = data.loc[data['Outcome'] == OUTCOME_ENCODES['ANY']]\n",
    "train_set  = data.loc[data['Outcome'] != OUTCOME_ENCODES['ANY']]\n",
    "\n",
    "# Create X_pred and y_pred as the predictors and target for the target set\n",
    "X_pred = target_set.drop('Outcome', axis=1)\n",
    "y_pred = target_set['Outcome']\n",
    "\n",
    "\n",
    "# Create X and y as the predictors and target for the training set\n",
    "X = train_set.drop('Outcome', axis=1)\n",
    "y = train_set['Outcome']\n",
    "\n",
    "# Split the training set into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.15,\n",
    "                                                    random_state=RANDOM_SEED,\n",
    "                                                    stratify=y)\n",
    "\n",
    "# Print the shape of each dataset\n",
    "print('X_train: '  + str(X_train.shape))\n",
    "print('y_train: '  + str(y_train.shape))\n",
    "print('X_test:  '  + str(X_test.shape))\n",
    "print('y_test:  '  + str(y_test.shape))\n",
    "print('X_pred: '   + str(X_pred.shape))\n",
    "print('y_pred: '   + str(y_pred.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4953145f",
   "metadata": {},
   "source": [
    "<a id=\"Remove_Outliers\"></a>\n",
    "### Remove Outliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc43a025",
   "metadata": {},
   "source": [
    "Removing outliers from the dataset is important to ensure that the machine learning models are trained on a representative sample of the data. Outliers can have a disproportionate impact on the model's performance and can skew the results. By removing outliers, we can ensure that the model is only trained on the most representative and relevant data, leading to improved accuracy and more robust results. Additionally, removing outliers can help to prevent overfitting, where the model is too heavily influenced by a small number of extreme points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fb2bcc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Observation_Value'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting boxplot of the 'Observation_Value' feature in the training set\n",
    "sns.boxplot(x=X_train['Observation_Value'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa44990a",
   "metadata": {},
   "source": [
    "The boxplot shows the distribution of the 'Observation_Value' feature in the training set.\n",
    "The box represents the interquartile range (IQR), which contains 50% of the data.\n",
    "The line inside the box represents the median, and the whiskers extend to the minimum and maximum values within 1.5 times the IQR.\n",
    "Any points outside of the whiskers are considered outliers and are plotted individually.\n",
    "This plot can be used to identify outliers from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bd3a814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range: 23.849999999999998\n",
      "Q1: 7.625\n",
      "Q3: 31.474999999999998\n"
     ]
    }
   ],
   "source": [
    "# Calculate interquartile range (IQR) and quartile 1 (Q1) and quartile 3 (Q3)\n",
    "# values for the 'Observation_Value' feature in the training set\n",
    "Q1 = X_train['Observation_Value'].quantile(0.25)\n",
    "Q3 = X_train['Observation_Value'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Print the calculated IQR, Q1, and Q3 values\n",
    "print(f'Range: {IQR}')\n",
    "print(f'Q1: {Q1}')\n",
    "print(f'Q3: {Q3}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a4a1e81",
   "metadata": {},
   "source": [
    "The IQR value represents the spread of the middle 50% of the data.\n",
    "The Q1 value is the first quartile, or 25th percentile, and Q3 is the third quartile, or 75th percentile.\n",
    "These values can be used to identify and remove outliers from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d5489ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounds: [-28.15,67.25]\n",
      "Bounds Range: 95.4\n"
     ]
    }
   ],
   "source": [
    "# Calculate lower and upper bounds for identifying outliers using the IQR value\n",
    "lower_bound = Q1 - (1.5 * IQR) \n",
    "upper_bound = Q3 + (1.5 * IQR)\n",
    "\n",
    "# Print the calculated lower and upper bounds\n",
    "# Values outside this range are considered outliers\n",
    "print(f'Bounds: [{lower_bound},{upper_bound}]')\n",
    "print(f'Bounds Range: {upper_bound-lower_bound}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74709dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 outliers:\n",
      "[1344, 1720, 1089, 1866]\n"
     ]
    }
   ],
   "source": [
    "# Identify the outliers by finding the rows whose Observation_Value is below lower_bound or above upper_bound\n",
    "outliers_rows = (X_train['Observation_Value'].index[(X_train['Observation_Value'] < lower_bound) |(X_train['Observation_Value'] > upper_bound)]).tolist()\n",
    "\n",
    "# Print the number of outliers and the index of the rows with outliers\n",
    "print(f'There are {len(outliers_rows)} outliers:')\n",
    "print(outliers_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2940176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "458\n"
     ]
    }
   ],
   "source": [
    "# Remove the rows containing outliers in the training set\n",
    "X_train = X_train.drop(outliers_rows, axis=0)\n",
    "y_train = y_train.drop(outliers_rows, axis=0)\n",
    "\n",
    "# Check if number of rows in X_train and y_train are equal after removing outliers\n",
    "print(X_train.shape[0] == y_train.shape[0])\n",
    "\n",
    "# Print the number of rows remaining in the training set\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01df21b9",
   "metadata": {},
   "source": [
    "<a id=\"Impute\"></a>\n",
    "### Impute"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f75e67ce",
   "metadata": {},
   "source": [
    "Imputing is necessary before training because it replaces missing values in the data with estimated values based on the other available information in the data. This helps to ensure that the model has a complete and accurate representation of the data to work with, reducing the risk of missing data impacting the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e34048eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using IterativeImputer to impute missing values in the datasets.\n",
    "# Setting the maximum number of iteration to 10 and random state to RANDOM_SEED for reproducibility.\n",
    "imp = IterativeImputer(max_iter=10, random_state=RANDOM_SEED)\n",
    "\n",
    "# Fit and transform the imputer on X_train dataset\n",
    "imputed_array = imp.fit_transform(X_train)\n",
    "\n",
    "# Convert the imputed array back to a dataframe with the same index and columns as the original X_train\n",
    "X_train = pd.DataFrame(imputed_array, index=X_train.index, columns=X_train.columns)\n",
    "\n",
    "# Impute missing values in X_test using the imputer fit on X_train\n",
    "imputed_array = imp.transform(X_test)\n",
    "# Convert the imputed array back to a dataframe with the same index and columns as the original X_test\n",
    "X_test = pd.DataFrame(imputed_array, index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "# Impute missing values in X_pred using the imputer fit on X_train\n",
    "imputed_array = imp.transform(X_pred)\n",
    "# Convert the imputed array back to a dataframe with the same index and columns as the original X_pred\n",
    "X_pred = pd.DataFrame(imputed_array, index=X_pred.index, columns=X_pred.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff5c886f",
   "metadata": {},
   "source": [
    "<a id=\"Scale\"></a>\n",
    "### Scale "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99ae6594",
   "metadata": {},
   "source": [
    "Scaling is necessary before training a machine learning model to ensure that all features have similar magnitude. This helps to avoid biased results due to the differences in scale between features and can improve model performance. Scaling also helps in better visualization of the data and better optimization in certain algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d08f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMaxScaler for normalizing the data in range of 0 to 1\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scaling the training set\n",
    "scaled_array = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(scaled_array, index=X_train.index, columns=X_train.columns)\n",
    "\n",
    "# Scaling the testing set\n",
    "scaled_array = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(scaled_array, index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "# Scaling the prediction set\n",
    "scaled_array = scaler.transform(X_pred)\n",
    "X_pred = pd.DataFrame(scaled_array, index=X_pred.index, columns=X_pred.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19f93232",
   "metadata": {},
   "source": [
    "<a id=\"PCA\"></a>\n",
    "### P.C.A. (Principal Component Analysis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "289e6a21",
   "metadata": {},
   "source": [
    "PCA, or Principal Component Analysis, is a dimensionality reduction technique that is applied before training to reduce the number of features in the data. This can improve the training time, reduce overfitting, and help capture the most important patterns in the data. By transforming the data into a new space with fewer dimensions, PCA can help simplify the data and make it easier for the machine learning model to understand the relationships between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f49fa975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA to the training data\n",
    "pca = PCA(random_state=RANDOM_SEED)\n",
    "pca = pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9a123b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine explained variance using explained_variance_ration_ attribute\n",
    "exp_var_pca = pca.explained_variance_ratio_\n",
    "\n",
    "# Cumulative sum of eigenvalues; This will be used to create step plot\n",
    "# for visualizing the variance explained by each principal component.\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "\n",
    "# Create the visualization plot\n",
    "plt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
    "plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8f43168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 22 components there is over 99% of information kept!\n"
     ]
    }
   ],
   "source": [
    "# Sum up the explained variance of each principal component\n",
    "total_var = 0\n",
    "\n",
    "# Loop through each explained variance\n",
    "for i, var in enumerate(exp_var_pca):\n",
    "    # Add the explained variance to the total\n",
    "    total_var += var\n",
    "\n",
    "    # If the cumulative sum of explained variance is greater than .99, print the number of components needed\n",
    "    # to retain 99% of information\n",
    "    if total_var > .99:\n",
    "        print(f'For {i+1} components there is over 99% of information kept!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7362fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "# The random_state is set to ensure the results are consistent across multiple runs\n",
    "pca = PCA(n_components=21, random_state=RANDOM_SEED)\n",
    "\n",
    "# Fit the PCA model on the training data and transform it into PCA components\n",
    "pca_array = pca.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(pca_array, index=X_train.index)\n",
    "\n",
    "# Transform the test set into PCA components\n",
    "pca_array = pca.transform(X_test)\n",
    "X_test = pd.DataFrame(pca_array, index=X_test.index)\n",
    "\n",
    "# Transform the predict set into PCA components\n",
    "pca_array = pca.transform(X_pred)\n",
    "X_pred = pd.DataFrame(pca_array, index=X_pred.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "557afc61",
   "metadata": {},
   "source": [
    "<a id=\"Data_Mining\"></a>\n",
    "## Data Mining"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ab1113d",
   "metadata": {},
   "source": [
    "<a id=\"Logistic_Regression\"></a>\n",
    "### Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00de4050",
   "metadata": {},
   "source": [
    "Logistic Regression is a statistical method for analyzing a dataset in which there are one or more independent variables that determine an outcome. It is used to model the probability of a certain class or event existing such as yes or no, true or false, 1 or 0, etc. It is commonly used in binary classification problems and also can be extended to multiclass problems through the use of one-vs-all or softmax functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a226bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.4, 'penalty': 'l2'}\n",
      "0.12006049506049507\n",
      "CPU times: total: 8.12 s\n",
      "Wall time: 816 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the Logistic Regression model\n",
    "logisticRegressor = LogisticRegression(multi_class='multinomial', \n",
    "                                       random_state=RANDOM_SEED,  # set the random seed for reproducibility\n",
    "                                       class_weight='balanced'    # set class weight to balanced to deal with class imbalance\n",
    "                                       )   \n",
    "\n",
    "# Define model parameters for the grid search\n",
    "param_grid = {'penalty':['l1', 'l2'],\n",
    "              'C': [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]}\n",
    "\n",
    "# Define the (10-Fold) Cross Validation Grid Search using f1_macro as the evaluation metric\n",
    "search = GridSearchCV(estimator=logisticRegressor,\n",
    "                      param_grid=param_grid,\n",
    "                      scoring='f1_macro',\n",
    "                      cv=10)\n",
    "\n",
    "# Fit the model to the training data\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by the grid search\n",
    "print(search.best_params_)\n",
    "# Print the best score achieved during the grid search\n",
    "print(search.best_score_)\n",
    "\n",
    "# Re-assign logisticRegressor to the best estimator from the grid search\n",
    "logisticRegressor = search.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfa9f3f0",
   "metadata": {},
   "source": [
    "<a id=\"K_Nearest_Neighbors\"></a>\n",
    "### K-Nearest Neighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fa33cfd",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (KNN) is a supervised machine learning algorithm used for both classification and regression. The idea behind KNN is to find the K nearest data points in the training set for a given test data point and make a prediction based on the class or numeric value of the majority of these neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "692386ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 33, 'p': 2, 'weights': 'uniform'}\n",
      "0.1344502235982112\n",
      "CPU times: total: 2min 22s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the K-Neighbors Classifier model using the minkowski metric\n",
    "kNearestNeighbors = KNeighborsClassifier(metric='minkowski')\n",
    "\n",
    "# Define model parameters for the grid search\n",
    "param_grid = {'n_neighbors':list(range(5,35)), # sqrt(435)~20 => [20-15,20+15] = [5,35]\n",
    "              'weights':['distance','uniform'],\n",
    "              'p':[1,2,3,4,5,6,7,8,9,10]}\n",
    "\n",
    "# Define the (10-Fold) Cross Validation Grid Search using f1_macro as the evaluation metric\n",
    "search = GridSearchCV(estimator=kNearestNeighbors,\n",
    "                      param_grid=param_grid,\n",
    "                      scoring='f1_macro',\n",
    "                      cv=10)\n",
    "\n",
    "# Fit the model to the training data\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by the grid search\n",
    "print(search.best_params_)\n",
    "# Print the best score achieved during the grid search\n",
    "print(search.best_score_)\n",
    "\n",
    "# Re-assign kNearestNeighbors to the best estimator from the grid search\n",
    "kNearestNeighbors = search.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a37ecacf",
   "metadata": {},
   "source": [
    "<a id=\"Disicion_Tree\"></a>\n",
    "### Disicion Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f017ee05",
   "metadata": {},
   "source": [
    "A decision tree is a tree-like model used in decision analysis and decision-making that splits data into branches based on conditions or rules, ultimately resulting in a prediction or decision. Each internal node of the tree represents a \"test\" on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "991ebedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 6, 'min_samples_leaf': 6, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "0.16102456432456433\n",
      "CPU times: total: 23.2 s\n",
      "Wall time: 23.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the Decision Tree Classifier model\n",
    "decisionTree = DecisionTreeClassifier(random_state=RANDOM_SEED, # set the random seed for reproducibility\n",
    "                                      class_weight='balanced')  # set class weight to balanced to deal with class imbalance\n",
    "\n",
    "# Define model parameters for the grid search\n",
    "param_grid = {'criterion':['gini','entropy'],\n",
    "              'splitter':['best','random'],\n",
    "              'max_depth':[2,3,4,5,6,7,8],\n",
    "              'min_samples_split':[2,3,4],\n",
    "              'min_samples_leaf':[2,3,4,5,6]}\n",
    "\n",
    "# Define the (10-Fold) Cross Validation Grid Search using f1_macro as the evaluation metric\n",
    "search = GridSearchCV(estimator=decisionTree,\n",
    "                      param_grid=param_grid,\n",
    "                      scoring='f1_macro',\n",
    "                      cv=10)\n",
    "\n",
    "# Fit the model to the training data\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by the grid search\n",
    "print(search.best_params_)\n",
    "# Print the best score achieved during the grid search\n",
    "print(search.best_score_)\n",
    "\n",
    "# Re-assign decisionTree to the best estimator from the grid search\n",
    "decisionTree = search.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f2b66aa",
   "metadata": {},
   "source": [
    "<a id=\"Support_Vector_Machine\"></a>\n",
    "### Support Vector Machine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d97135f3",
   "metadata": {},
   "source": [
    "Support Vector Machines (SVM) is a type of supervised learning algorithm used for classification and regression analysis. The SVM algorithm finds a boundary that separates the data into classes by maximizing the margin, i.e., the distance between the closest data points from each class, known as support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87c7d39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 128, 'coef0': 0, 'gamma': 0.5, 'kernel': 'sigmoid'}\n",
      "0.1795047619047619\n",
      "CPU times: total: 7min 25s\n",
      "Wall time: 7min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define the Support Vector Machine Classifier model\n",
    "supportVectorMachine = SVC(random_state=RANDOM_SEED, # set the random seed for reproducibility\n",
    "                           class_weight='balanced')  # set class weight to balanced to deal with class imbalance\n",
    "\n",
    "# Define model parameters for the grid search\n",
    "param_grid = [{'kernel':['linear'],\n",
    "               'C':[0.125, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512]},\n",
    "              {'kernel':['poly'],\n",
    "               'degree':[2,3,4,5,6,7,8],\n",
    "               'coef0':[0,1],\n",
    "               'gamma':[0.00390625, 0.0078125, 0.015625, 0.03125, 0.0625, 0.125, 0.5, 1, 2, 4],\n",
    "               'C':[0.125, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512]},\n",
    "              {'kernel':['rbf'],\n",
    "               'gamma':[0.00390625, 0.0078125, 0.015625, 0.03125, 0.0625, 0.125, 0.5, 1, 2, 4],\n",
    "               'C':[0.125, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512]},\n",
    "              {'kernel':['sigmoid'],\n",
    "               'coef0':[0,1],\n",
    "               'gamma':[0.00390625, 0.0078125, 0.015625, 0.03125, 0.0625, 0.125, 0.5, 1, 2, 4],\n",
    "               'C':[0.125, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512]}]\n",
    "\n",
    "# Define the (10-Fold) Cross Validation Grid Search using f1_macro as the evaluation metric\n",
    "search = GridSearchCV(estimator=supportVectorMachine,\n",
    "                      param_grid=param_grid,\n",
    "                      scoring='f1_macro',\n",
    "                      cv=10)\n",
    "\n",
    "# Fit the model to the training data\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by the grid search\n",
    "print(search.best_params_)\n",
    "# Print the best score achieved during the grid search\n",
    "print(search.best_score_)\n",
    "\n",
    "# Re-assign supportVectorMachine to the best estimator from the grid search\n",
    "supportVectorMachine = search.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f679ee69",
   "metadata": {},
   "source": [
    "<a id=\"Random_Forest\"></a>\n",
    "### Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c412b2de",
   "metadata": {},
   "source": [
    "Random Forest is an ensemble learning method for classification and regression that operates by constructing a multitude of decision trees and aggregating their predictions. It uses bootstrapped samples of the input data and a random subset of the features at each split of each decision tree to reduce overfitting and increase model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03a816c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 5}\n",
      "0.16004679764679766\n",
      "CPU times: total: 7min 49s\n",
      "Wall time: 7min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define the Random Forest Classifier model\n",
    "randomForest = RandomForestClassifier(random_state=RANDOM_SEED, # set the random seed for reproducibility\n",
    "                                      class_weight='balanced')  # set class weight to balanced to deal with class imbalance\n",
    "\n",
    "# Define model parameters for the grid search\n",
    "param_grid = {'n_estimators':[5,10,15,20,25,30,35,40],\n",
    "              'criterion':['gini','entropy'],\n",
    "              'max_depth':[3,4,5,6,7,8],\n",
    "              'min_samples_split':[2,3,4,5],\n",
    "              'min_samples_leaf':[1,2,3]}\n",
    "\n",
    "# Define the (10-Fold) Cross Validation Grid Search using f1_macro as the evaluation metric\n",
    "search = GridSearchCV(estimator=randomForest,\n",
    "                      param_grid=param_grid,\n",
    "                      scoring='f1_macro',\n",
    "                      cv=10)\n",
    "\n",
    "# Fit the model to the training data\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by the grid search\n",
    "print(search.best_params_)\n",
    "# Print the best score achieved during the grid search\n",
    "print(search.best_score_)\n",
    "\n",
    "# Re-assign randomForest to the best estimator from the grid search\n",
    "randomForest = search.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8feb03b",
   "metadata": {},
   "source": [
    "<a id=\"XGBoosting\"></a>\n",
    "### XGBoosting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72aa8cc0",
   "metadata": {},
   "source": [
    "XGBoost (eXtreme Gradient Boosting) is an optimized and scalable gradient boosting library designed for high-performance machine learning. It is an efficient and effective implementation of the gradient boosting algorithm, combining speed, memory efficiency, and a high level of parallelism to achieve improved accuracy and performance on a variety of machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b9ad090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:51:37] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:38] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:38] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:39] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:49] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:50] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:50] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:51] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:52] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:53] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:53] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:54] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:55] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:56] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:56] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:57] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:58] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:59] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:51:59] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:00] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:01] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:02] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:03] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:03] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:04] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:05] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:06] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:07] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:07] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:08] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:09] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:10] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:11] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:11] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:12] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:13] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:14] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:14] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:15] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:16] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:17] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:21] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:21] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:22] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:23] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:24] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:24] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:25] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:26] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:27] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:28] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:29] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:29] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "[19:52:30] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "{'n_estimators': 125}\n",
      "0.09603929469223586\n",
      "CPU times: total: 16min 42s\n",
      "Wall time: 53.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the XGBoost Classifier model\n",
    "xGBoost = XGBClassifier(random_state=RANDOM_SEED, # set the random seed for reproducibility\n",
    "                        class_weight='balanced')  # set class weight to balanced to deal with class imbalance\n",
    "\n",
    "# Define model parameters for the grid search\n",
    "param_grid = {'n_estimators':[125,130,135,140,145,150,155]}\n",
    "\n",
    "# Define the (10-Fold) Cross Validation Grid Search using f1_macro as the evaluation metric\n",
    "search = GridSearchCV(estimator=xGBoost,\n",
    "                      param_grid=param_grid,\n",
    "                      scoring='f1_macro',\n",
    "                      cv=10)\n",
    "\n",
    "# Fit the model to the training data\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by the grid search\n",
    "print(search.best_params_)\n",
    "# Print the best score achieved during the grid search\n",
    "print(search.best_score_)\n",
    "\n",
    "# Re-assign xGBoost to the best estimator from the grid search\n",
    "xGBoost = search.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfaf3810",
   "metadata": {},
   "source": [
    "<a id=\"Evaluation_Interpretation\"></a>\n",
    "## Evaluation Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c48e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_func(model, X_train, X_test, y_train, y_test):\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model to make predictions on the test data\n",
    "    y_hat = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy of the model's predictions\n",
    "    accuracy = metrics.accuracy_score(y_test,y_hat)\n",
    "    # Calculate the precision of the model's predictions\n",
    "    precision = metrics.precision_score(y_test,y_hat,average='macro')\n",
    "    # Calculate the recall of the model's predictions\n",
    "    recall = metrics.recall_score(y_test,y_hat,average='macro')\n",
    "    # Calculate the F1 score of the model's predictions\n",
    "    f1 = metrics.f1_score(y_test,y_hat,average='macro')\n",
    "    \n",
    "    # Return a list of evaluation metrics\n",
    "    return [accuracy,precision,recall,f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e51a1c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:52:52] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Lists of models to evaluate\n",
    "models = [logisticRegressor,\n",
    "          kNearestNeighbors,\n",
    "          decisionTree,\n",
    "          supportVectorMachine,\n",
    "          randomForest,\n",
    "          xGBoost]\n",
    "\n",
    "# Lists to store evaluation metrics for each model\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Loop through each model in the list\n",
    "for model in models:\n",
    "    # Use the evaluation function to calculate scores\n",
    "    [acc,pre,rec,f1] = evaluation_func(model, X_train, X_test, y_train, y_test)\n",
    "    # Append the scores to the corresponding lists\n",
    "    accuracy_scores.append(acc)\n",
    "    precision_scores.append(pre)\n",
    "    recall_scores.append(rec)\n",
    "    f1_scores.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a95d7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Labels for each model\n",
    "labels = ['Logistic Regression', 'kNN', 'Decision Tree', 'SVM', 'Random Forest', 'XGBoost']\n",
    "# Locations for each label\n",
    "x = np.arange(len(labels))*2.5\n",
    "# Width of each bar\n",
    "width = 0.50\n",
    "\n",
    "# Initialize plot and axes\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create grouped bar chart\n",
    "rects1 = ax.bar(x - 0.75, accuracy_scores, width, label='Accuracy')\n",
    "rects2 = ax.bar(x - 0.25, precision_scores, width, label='Precision')\n",
    "rects3 = ax.bar(x + 0.25, recall_scores, width, label='Recall')\n",
    "rects4 = ax.bar(x + 0.75, f1_scores, width, label='F1')\n",
    "\n",
    "# Add label to y-axis\n",
    "ax.set_ylabel('Scores')\n",
    "# Add x-axis tick labels\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Add value labels to each bar\n",
    "ax.bar_label(rects1, fmt='%.2f', fontsize=9, rotation=90, padding=2)\n",
    "ax.bar_label(rects2, fmt='%.2f', fontsize=9, rotation=90, padding=2)\n",
    "ax.bar_label(rects3, fmt='%.2f', fontsize=9, rotation=90, padding=2)\n",
    "ax.bar_label(rects4, fmt='%.2f', fontsize=9, rotation=90, padding=2)\n",
    "\n",
    "# Adjust plot layout\n",
    "fig.tight_layout(rect=(0,0,1.2,1.1))\n",
    "\n",
    "# Remove spines\n",
    "sns.despine()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff53b813",
   "metadata": {},
   "source": [
    "<a id=\"Prediction\"></a>\n",
    "## Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e4a8d49",
   "metadata": {},
   "source": [
    "Given the results, it can be seen that the Support Vector Machine model performed the best, thus it will be utilized to predict the missing values for the target feature (ANY)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f9d63a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "supportVectorMachine.fit(X_train, y_train)\n",
    "\n",
    "y_hat = model.predict(X_pred)\n",
    "y_hat = pd.Series(y_hat, name='Outcome', index=X_pred.index) # Convert to pd.Series with correct index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d270614",
   "metadata": {},
   "source": [
    "### Merge_All_Three_SubDatasets_Back_to_One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ae0f02ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vaw_train: (429, 22)\n",
      "vaw_test: (109, 22)\n",
      "vaw_pred:  (1472, 22)\n"
     ]
    }
   ],
   "source": [
    "# Concat horisontaly\n",
    "vaw_train = pd.concat([X_train, y_train], axis=1)\n",
    "vaw_test = pd.concat([X_test, y_test], axis=1)\n",
    "vaw_pred = pd.concat([X_pred, y_hat], axis=1)\n",
    "\n",
    "# Shape of dataset\n",
    "print('vaw_train: ' + str(vaw_train.shape))\n",
    "print('vaw_test: ' + str(vaw_test.shape))\n",
    "print('vaw_pred:  '  + str(vaw_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a363f47f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P.Comp_01</th>\n",
       "      <th>P.Comp_02</th>\n",
       "      <th>P.Comp_03</th>\n",
       "      <th>P.Comp_04</th>\n",
       "      <th>P.Comp_05</th>\n",
       "      <th>P.Comp_06</th>\n",
       "      <th>P.Comp_07</th>\n",
       "      <th>P.Comp_08</th>\n",
       "      <th>P.Comp_09</th>\n",
       "      <th>P.Comp_10</th>\n",
       "      <th>P.Comp_11</th>\n",
       "      <th>P.Comp_12</th>\n",
       "      <th>P.Comp_13</th>\n",
       "      <th>P.Comp_14</th>\n",
       "      <th>P.Comp_15</th>\n",
       "      <th>P.Comp_16</th>\n",
       "      <th>P.Comp_17</th>\n",
       "      <th>P.Comp_18</th>\n",
       "      <th>P.Comp_19</th>\n",
       "      <th>P.Comp_20</th>\n",
       "      <th>P.Comp_21</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.095146</td>\n",
       "      <td>-0.270775</td>\n",
       "      <td>-0.160796</td>\n",
       "      <td>0.056499</td>\n",
       "      <td>0.263191</td>\n",
       "      <td>0.094090</td>\n",
       "      <td>0.193086</td>\n",
       "      <td>0.202750</td>\n",
       "      <td>0.450894</td>\n",
       "      <td>-0.162408</td>\n",
       "      <td>-0.019386</td>\n",
       "      <td>-0.189745</td>\n",
       "      <td>0.203501</td>\n",
       "      <td>-0.014376</td>\n",
       "      <td>0.328980</td>\n",
       "      <td>0.594006</td>\n",
       "      <td>-0.500987</td>\n",
       "      <td>0.458466</td>\n",
       "      <td>-0.144457</td>\n",
       "      <td>0.144544</td>\n",
       "      <td>-0.133649</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.184818</td>\n",
       "      <td>-0.178934</td>\n",
       "      <td>-0.254737</td>\n",
       "      <td>0.034532</td>\n",
       "      <td>0.331010</td>\n",
       "      <td>0.116268</td>\n",
       "      <td>0.194603</td>\n",
       "      <td>-0.474799</td>\n",
       "      <td>0.634516</td>\n",
       "      <td>-0.238699</td>\n",
       "      <td>0.059973</td>\n",
       "      <td>-0.154528</td>\n",
       "      <td>0.179162</td>\n",
       "      <td>-0.017794</td>\n",
       "      <td>0.309899</td>\n",
       "      <td>0.595497</td>\n",
       "      <td>-0.511303</td>\n",
       "      <td>0.511923</td>\n",
       "      <td>-0.148456</td>\n",
       "      <td>0.084257</td>\n",
       "      <td>-0.133387</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.237574</td>\n",
       "      <td>-0.115207</td>\n",
       "      <td>-0.200532</td>\n",
       "      <td>-0.011499</td>\n",
       "      <td>0.130076</td>\n",
       "      <td>-0.009226</td>\n",
       "      <td>0.228233</td>\n",
       "      <td>0.881630</td>\n",
       "      <td>0.304834</td>\n",
       "      <td>-0.129532</td>\n",
       "      <td>0.102924</td>\n",
       "      <td>-0.195364</td>\n",
       "      <td>0.180656</td>\n",
       "      <td>-0.004536</td>\n",
       "      <td>0.356172</td>\n",
       "      <td>0.546696</td>\n",
       "      <td>-0.459488</td>\n",
       "      <td>0.420419</td>\n",
       "      <td>-0.159465</td>\n",
       "      <td>0.086078</td>\n",
       "      <td>-0.159865</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.285659</td>\n",
       "      <td>-0.150339</td>\n",
       "      <td>-0.289820</td>\n",
       "      <td>0.029470</td>\n",
       "      <td>0.353184</td>\n",
       "      <td>0.111596</td>\n",
       "      <td>0.173367</td>\n",
       "      <td>-0.434884</td>\n",
       "      <td>0.688644</td>\n",
       "      <td>-0.191000</td>\n",
       "      <td>0.428473</td>\n",
       "      <td>-0.128052</td>\n",
       "      <td>0.172569</td>\n",
       "      <td>-0.030816</td>\n",
       "      <td>0.113693</td>\n",
       "      <td>0.345776</td>\n",
       "      <td>-0.362756</td>\n",
       "      <td>1.135812</td>\n",
       "      <td>-0.271234</td>\n",
       "      <td>0.084436</td>\n",
       "      <td>-0.036880</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.345141</td>\n",
       "      <td>-0.075935</td>\n",
       "      <td>-0.225586</td>\n",
       "      <td>-0.029478</td>\n",
       "      <td>0.132346</td>\n",
       "      <td>-0.027542</td>\n",
       "      <td>0.216382</td>\n",
       "      <td>0.928776</td>\n",
       "      <td>0.366435</td>\n",
       "      <td>-0.107082</td>\n",
       "      <td>0.489098</td>\n",
       "      <td>-0.160765</td>\n",
       "      <td>0.157516</td>\n",
       "      <td>-0.016043</td>\n",
       "      <td>0.160051</td>\n",
       "      <td>0.284551</td>\n",
       "      <td>-0.303923</td>\n",
       "      <td>1.043480</td>\n",
       "      <td>-0.284147</td>\n",
       "      <td>0.077171</td>\n",
       "      <td>-0.083043</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>-0.049534</td>\n",
       "      <td>0.163366</td>\n",
       "      <td>0.560462</td>\n",
       "      <td>0.155557</td>\n",
       "      <td>0.536468</td>\n",
       "      <td>0.171218</td>\n",
       "      <td>-0.005066</td>\n",
       "      <td>-0.043865</td>\n",
       "      <td>-0.171883</td>\n",
       "      <td>0.555886</td>\n",
       "      <td>0.059725</td>\n",
       "      <td>0.391102</td>\n",
       "      <td>-0.119554</td>\n",
       "      <td>-0.015795</td>\n",
       "      <td>0.044403</td>\n",
       "      <td>-0.442672</td>\n",
       "      <td>-0.457955</td>\n",
       "      <td>-0.061588</td>\n",
       "      <td>0.066864</td>\n",
       "      <td>0.179926</td>\n",
       "      <td>-0.149922</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>-0.060819</td>\n",
       "      <td>0.145451</td>\n",
       "      <td>0.543632</td>\n",
       "      <td>0.177232</td>\n",
       "      <td>0.569866</td>\n",
       "      <td>0.194113</td>\n",
       "      <td>-0.020814</td>\n",
       "      <td>-0.056000</td>\n",
       "      <td>-0.184423</td>\n",
       "      <td>0.598255</td>\n",
       "      <td>0.030067</td>\n",
       "      <td>0.377471</td>\n",
       "      <td>-0.091788</td>\n",
       "      <td>-0.018338</td>\n",
       "      <td>0.044259</td>\n",
       "      <td>-0.421826</td>\n",
       "      <td>-0.469732</td>\n",
       "      <td>-0.060198</td>\n",
       "      <td>0.070058</td>\n",
       "      <td>0.195173</td>\n",
       "      <td>-0.116890</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>-0.054619</td>\n",
       "      <td>0.155293</td>\n",
       "      <td>0.552878</td>\n",
       "      <td>0.165324</td>\n",
       "      <td>0.551518</td>\n",
       "      <td>0.181535</td>\n",
       "      <td>-0.012163</td>\n",
       "      <td>-0.049333</td>\n",
       "      <td>-0.177534</td>\n",
       "      <td>0.574979</td>\n",
       "      <td>0.046361</td>\n",
       "      <td>0.384960</td>\n",
       "      <td>-0.107042</td>\n",
       "      <td>-0.016941</td>\n",
       "      <td>0.044338</td>\n",
       "      <td>-0.433278</td>\n",
       "      <td>-0.463262</td>\n",
       "      <td>-0.060962</td>\n",
       "      <td>0.068303</td>\n",
       "      <td>0.186797</td>\n",
       "      <td>-0.135037</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>-0.064917</td>\n",
       "      <td>0.138945</td>\n",
       "      <td>0.537521</td>\n",
       "      <td>0.185104</td>\n",
       "      <td>0.581995</td>\n",
       "      <td>0.202427</td>\n",
       "      <td>-0.026533</td>\n",
       "      <td>-0.060406</td>\n",
       "      <td>-0.188976</td>\n",
       "      <td>0.613642</td>\n",
       "      <td>0.019297</td>\n",
       "      <td>0.372522</td>\n",
       "      <td>-0.081705</td>\n",
       "      <td>-0.019262</td>\n",
       "      <td>0.044207</td>\n",
       "      <td>-0.414255</td>\n",
       "      <td>-0.474009</td>\n",
       "      <td>-0.059694</td>\n",
       "      <td>0.071219</td>\n",
       "      <td>0.200710</td>\n",
       "      <td>-0.104895</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>-0.064077</td>\n",
       "      <td>0.140280</td>\n",
       "      <td>0.538774</td>\n",
       "      <td>0.183489</td>\n",
       "      <td>0.579507</td>\n",
       "      <td>0.200721</td>\n",
       "      <td>-0.025360</td>\n",
       "      <td>-0.059502</td>\n",
       "      <td>-0.188042</td>\n",
       "      <td>0.610485</td>\n",
       "      <td>0.021506</td>\n",
       "      <td>0.373537</td>\n",
       "      <td>-0.083773</td>\n",
       "      <td>-0.019072</td>\n",
       "      <td>0.044217</td>\n",
       "      <td>-0.415808</td>\n",
       "      <td>-0.473131</td>\n",
       "      <td>-0.059797</td>\n",
       "      <td>0.070981</td>\n",
       "      <td>0.199574</td>\n",
       "      <td>-0.107355</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2010 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      P.Comp_01  P.Comp_02  P.Comp_03  P.Comp_04  P.Comp_05  P.Comp_06  \\\n",
       "0     -0.095146  -0.270775  -0.160796   0.056499   0.263191   0.094090   \n",
       "1      0.184818  -0.178934  -0.254737   0.034532   0.331010   0.116268   \n",
       "2      0.237574  -0.115207  -0.200532  -0.011499   0.130076  -0.009226   \n",
       "3      0.285659  -0.150339  -0.289820   0.029470   0.353184   0.111596   \n",
       "4      0.345141  -0.075935  -0.225586  -0.029478   0.132346  -0.027542   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2011  -0.049534   0.163366   0.560462   0.155557   0.536468   0.171218   \n",
       "2012  -0.060819   0.145451   0.543632   0.177232   0.569866   0.194113   \n",
       "2013  -0.054619   0.155293   0.552878   0.165324   0.551518   0.181535   \n",
       "2014  -0.064917   0.138945   0.537521   0.185104   0.581995   0.202427   \n",
       "2015  -0.064077   0.140280   0.538774   0.183489   0.579507   0.200721   \n",
       "\n",
       "      P.Comp_07  P.Comp_08  P.Comp_09  P.Comp_10  P.Comp_11  P.Comp_12  \\\n",
       "0      0.193086   0.202750   0.450894  -0.162408  -0.019386  -0.189745   \n",
       "1      0.194603  -0.474799   0.634516  -0.238699   0.059973  -0.154528   \n",
       "2      0.228233   0.881630   0.304834  -0.129532   0.102924  -0.195364   \n",
       "3      0.173367  -0.434884   0.688644  -0.191000   0.428473  -0.128052   \n",
       "4      0.216382   0.928776   0.366435  -0.107082   0.489098  -0.160765   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2011  -0.005066  -0.043865  -0.171883   0.555886   0.059725   0.391102   \n",
       "2012  -0.020814  -0.056000  -0.184423   0.598255   0.030067   0.377471   \n",
       "2013  -0.012163  -0.049333  -0.177534   0.574979   0.046361   0.384960   \n",
       "2014  -0.026533  -0.060406  -0.188976   0.613642   0.019297   0.372522   \n",
       "2015  -0.025360  -0.059502  -0.188042   0.610485   0.021506   0.373537   \n",
       "\n",
       "      P.Comp_13  P.Comp_14  P.Comp_15  P.Comp_16  P.Comp_17  P.Comp_18  \\\n",
       "0      0.203501  -0.014376   0.328980   0.594006  -0.500987   0.458466   \n",
       "1      0.179162  -0.017794   0.309899   0.595497  -0.511303   0.511923   \n",
       "2      0.180656  -0.004536   0.356172   0.546696  -0.459488   0.420419   \n",
       "3      0.172569  -0.030816   0.113693   0.345776  -0.362756   1.135812   \n",
       "4      0.157516  -0.016043   0.160051   0.284551  -0.303923   1.043480   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2011  -0.119554  -0.015795   0.044403  -0.442672  -0.457955  -0.061588   \n",
       "2012  -0.091788  -0.018338   0.044259  -0.421826  -0.469732  -0.060198   \n",
       "2013  -0.107042  -0.016941   0.044338  -0.433278  -0.463262  -0.060962   \n",
       "2014  -0.081705  -0.019262   0.044207  -0.414255  -0.474009  -0.059694   \n",
       "2015  -0.083773  -0.019072   0.044217  -0.415808  -0.473131  -0.059797   \n",
       "\n",
       "      P.Comp_19  P.Comp_20  P.Comp_21  Outcome  \n",
       "0     -0.144457   0.144544  -0.133649       22  \n",
       "1     -0.148456   0.084257  -0.133387       22  \n",
       "2     -0.159465   0.086078  -0.159865       14  \n",
       "3     -0.271234   0.084436  -0.036880        9  \n",
       "4     -0.284147   0.077171  -0.083043       14  \n",
       "...         ...        ...        ...      ...  \n",
       "2011   0.066864   0.179926  -0.149922       23  \n",
       "2012   0.070058   0.195173  -0.116890       23  \n",
       "2013   0.068303   0.186797  -0.135037       23  \n",
       "2014   0.071219   0.200710  -0.104895       23  \n",
       "2015   0.070981   0.199574  -0.107355       23  \n",
       "\n",
       "[2010 rows x 22 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat with respect to index (verticaly)\n",
    "vaw_v4 = pd.concat([vaw_train, vaw_test, vaw_pred], axis=0).sort_index()\n",
    "\n",
    "# Change the col names (P.Comp = Principal Component)\n",
    "column_names = []\n",
    "\n",
    "for i in range(21):\n",
    "    column_names.append(f'P.Comp_{(i+1):02d}')\n",
    "    \n",
    "column_names.append('Outcome')\n",
    "vaw_v4.columns = column_names\n",
    "# Final Dataset\n",
    "vaw_v4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4f24030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaw_v4.to_csv('datasets/New_VAW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00203096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d71e46519c1860df6c1f963fbbc8994725cfda379f229f7ac63ce4f5eda852b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
